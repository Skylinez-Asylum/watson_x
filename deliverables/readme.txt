Introduction: Unmasking Bias: In Pursuit of Fairness

Welcome to the Unmasking Bias: In Pursuit of Fairness
GitHub repository. This project focuses on developing an AI model that identifies and addresses biases within texts and documents. Our goal is to enhance fairness and reduce bias in natural language processing (NLP) applications. By leveraging advanced machine learning techniques, this model can detect subtle and overt biases, providing insights and adjustments to promote equity in language use.

This repository contains the codebase, data, and documentation necessary to understand, implement, and improve the bias detection and mitigation processes. We encourage collaboration and contributions to refine the model and expand its capabilities. Together, we can strive for a more fair and unbiased digital world.


Prerequisites:	python,git


Installation: git clone https://github.com/Skylinez-Asylum/watson_x.git
	      cd watson_x
              pip install -r requirements.txt

Running the code: streamlit run watson_x.py

Usage:Upload pdf and click analyze text

Troubleshooting: if any nltk error occurs add a line of code nltk.download("all")
		if any api key error occur. create a new api key
